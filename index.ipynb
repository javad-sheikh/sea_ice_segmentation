{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from pathlib import Path\n",
    "\n",
    "import fastai\n",
    "import sklearn\n",
    "import torch\n",
    "from fastai.callbacks import CSVLogger, SaveModelCallback\n",
    "from fastai.vision import *\n",
    "from sea_ice_segmentation.models import *\n",
    "from sea_ice_segmentation.postprocessing import conv_crf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea-ice segmentation\n",
    "\n",
    "> This repository contains code for the paper titled 'Supplementing remote sensing of ice: Deep learning-based image segmentation system for automatic detection and localization of sea-ice formations from close-range optical images'. \n",
    "\n",
    "If you use this code, please cite: \n",
    "\n",
    "**N. Panchi, E. Kim and A. Bhattacharyya, \"Supplementing remote sensing of ice: Deep learning-based image segmentation system for automatic detection and localization of sea ice formations from close-range optical images,\" in IEEE Sensors Journal, doi: 10.1109/JSEN.2021.3084556.**\n",
    "\n",
    "More documentation and code will be added soon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder structure**\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "└── data\n",
    "    └── images\n",
    "    └── labels\n",
    "    └── validation.txt\n",
    "```\n",
    "\n",
    "```images```: Contains all the images (.jpg).\n",
    "\n",
    "```labels```: Contains all the labels (.png).\n",
    "\n",
    "```validation.txt```: Contains the names of the images to be used for validation (one line contains one image name, with extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./data\")\n",
    "path_img = path / \"images\"\n",
    "path_lbl = path / \"labels\"\n",
    "validation_file = \"../validation.txt\"  # Relative to path_img\n",
    "\n",
    "\n",
    "img_size = 512  # 512x512 pixels\n",
    "batch_size = 2\n",
    "classes = [\n",
    "    \"Brash ice\",\n",
    "    \"Deformed ice\",\n",
    "    \"Floeberg\",\n",
    "    \"Floebit\",\n",
    "    \"Ice floe\",\n",
    "    \"Iceberg\",\n",
    "    \"Level ice\",\n",
    "    \"Melt pond\",\n",
    "    \"Open water\",\n",
    "    \"Pancake ice\",\n",
    "    \"Shore\",\n",
    "    \"Sky\",\n",
    "    \"Underwater ice\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_img(img_file, path_lbl=path_lbl):\n",
    "    return path_lbl / f\"{img_file.stem}_mask.png\"\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    path_img=path_img,\n",
    "    path_lbl=path_lbl,\n",
    "    validation_file=validation_file,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    classes=classes,\n",
    "):\n",
    "    \"\"\"Get the dataset object\"\"\"\n",
    "\n",
    "    tfms = get_transforms(do_flip=True, max_rotate=5, max_lighting=0.1)\n",
    "\n",
    "    data = (\n",
    "        SegmentationItemList.from_folder(path_img)\n",
    "        .split_by_fname_file(validation_file)\n",
    "        .label_from_func(get_label_from_img, classes=classes)\n",
    "        .transform(tfms, size=img_size, tfm_y=True)\n",
    "        .databunch(bs=batch_size)\n",
    "        .normalize(imagenet_stats)\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(\n",
    "    path_img=path_img,\n",
    "    path_lbl=path_lbl,\n",
    "    validation_file=validation_file,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y_pred, y_true, argmax=True, average=\"macro\"):\n",
    "    \"\"\"\n",
    "    A wrapper around the sklearn method `fbeta_score`.\n",
    "    Computes the F-beta score between `y_pred` and `y_true`.\n",
    "    \"\"\"\n",
    "\n",
    "    if argmax:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "\n",
    "    n = y_pred.shape[0]\n",
    "    y_true = y_true.float().view(n, -1)\n",
    "    y_pred = y_pred.float().view(n, -1)\n",
    "\n",
    "    scores = torch.zeros(n)\n",
    "    for i in range(n):\n",
    "        scores[i] = sklearn.metrics.fbeta_score(\n",
    "            to_np(y_true[i]), to_np(y_pred[i]), beta=1, average=average\n",
    "        )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def Accuracy(y_pred, y_true, argmax=True):\n",
    "    \"\"\"Computes accuracy between `y_pred` and `y_true`.\"\"\"\n",
    "\n",
    "    if argmax:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "\n",
    "    y_pred = y_pred.squeeze(1).float()\n",
    "    y_true = y_true.squeeze(1).float()\n",
    "\n",
    "    return (y_pred == y_true).float().mean()\n",
    "\n",
    "\n",
    "def one_hot(y_pred, y_true, argmax=True):\n",
    "    \"\"\"Helper function for calcuation of IOU.\"\"\"\n",
    "\n",
    "    n, c, h, w = y_pred.shape\n",
    "\n",
    "    range_tensor_ = to_device(\n",
    "        torch.stack([torch.arange(c)] * w * h, dim=1).view(c, -1), y_pred.device\n",
    "    )\n",
    "    range_tensor_batch_ = to_device(\n",
    "        torch.stack([range_tensor_] * n, dim=1).float(), y_pred.device\n",
    "    )\n",
    "\n",
    "    if argmax:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "\n",
    "    y_pred_ = to_device(torch.stack([y_pred] * c).float().view(c, n, -1), y_pred.device)\n",
    "    y_true_ = to_device(\n",
    "        torch.stack([y_true.squeeze(1)] * c).float().view(c, n, -1), y_pred.device\n",
    "    )\n",
    "\n",
    "    y_pred_ = (y_pred_ == range_tensor_batch_).float()\n",
    "    y_true_ = (y_true_ == range_tensor_batch_).float()\n",
    "    return y_pred_, y_true_, n, c, h, w\n",
    "\n",
    "\n",
    "def Mean_IoU(y_pred, y_true, argmax=True, eps=1e-15):\n",
    "    \"\"\"Calculates mean IoU between `y_pred` and `y_true`\"\"\"\n",
    "\n",
    "    y_pred, y_true, n, c, h, w = one_hot(y_pred, y_true, argmax)\n",
    "\n",
    "    intersection = (y_pred * y_true).sum(dim=2).float()\n",
    "    union = (y_pred + y_true).sum(dim=2).float()\n",
    "    ious = (intersection + eps) / (union - intersection + eps)\n",
    "\n",
    "    res = ious.sum(dim=1) / n\n",
    "    res = res.sum() / (c)\n",
    "    return tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [Mean_IoU, Accuracy, F1_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pspnet = PSPNet(num_classes=len(classes), backbone=\"resnet152\", pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc_fn = conv_crf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = True  # Initialize the neural network using Kaiming normalization\n",
    "wd = 1e-2  # Weight decay parameter\n",
    "half_prec = True  # Half precision training\n",
    "epochs = [20, 60]  # Stage 1: 20 training epochs, Stage 2: 60 training epochs\n",
    "lr1 = 5e-3  # Learning rate for stage 1\n",
    "lr2 = [lr / 40, lr / 4]  # Learning rates for stage 2\n",
    "pct_starts = [\n",
    "    0.9,\n",
    "    0.9,\n",
    "]  # Increase the lr from a min value to the given lr in first 90% of the training iterations in both stage 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data, model, init, metrics, wd):\n",
    "    model = to_device(model, data.device)\n",
    "    learn = Learner(data=data, model=model, metrics=metrics, wd=wd)\n",
    "    learn.split(model.split_model)\n",
    "\n",
    "    if model.pretrained and len(learn.layer_groups) > 1:\n",
    "        learn.freeze()\n",
    "    if init:\n",
    "        apply_init(model, torch.nn.init.kaiming_normal_)\n",
    "\n",
    "    return learn\n",
    "\n",
    "\n",
    "def train(data, model, init, metrics, wd, half_prec, epochs, lr1, lr2, pct_starts, postproc_fn):\n",
    "      \n",
    "    model_name = type(model).__name__\n",
    "    learn = get_learner(data, model, init, metrics, wd)\n",
    "    if half_prec: learn = learn.to_fp16()\n",
    "    \n",
    "    #stage 1\n",
    "    print(f\"Stage 1 training...\")\n",
    "    name1 = f'Stage_1-{model_name}\"\n",
    "    learn.fit_one_cycle(epochs[0], slice(lr1), pct_start=pct_starts[0], \n",
    "                        callbacks=[SaveModelCallback(learn, every='improvement', monitor='meanIOU-ConvCRF', mode='max', name=name1), \n",
    "                        CSVLogger(learn=learn, filename=f\"../../results/{model_name}\"),  #filename is relative to the path_img\n",
    "                        *get_metrics_callbacks(learn, metrics, postproc_fn)])\n",
    "\n",
    "    #stage 2\n",
    "    learn.unfreeze()\n",
    "    print(f\"Stage 2 training...\")\n",
    "    name2 = f'Stage_2-{model_name}\"\n",
    "    learn.fit_one_cycle(epochs[1], slice(lr2), pct_start=pct_starts[1], \n",
    "                        callbacks=[SaveModelCallback(learn, every='improvement', monitor='meanIOU-ConvCRF', mode='max', name=name2), \n",
    "                        CSVLogger(learn=learn, filename=f\"../../results/{model_name}\", append=True),  #filename is relative to the path_img\n",
    "                        *get_metrics_callbacks(learn, metrics, postproc_fn)])\n",
    "    \n",
    "    learn.load(name2);\n",
    "                                   \n",
    "    learn.name1, learn.name2 = name1, name2\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = train(\n",
    "    data, model, init, metrics, wd, half_prec, epochs, lr1, lr2, pct_starts, postproc_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- The implementation of the deep learning models was derived from https://github.com/yassouali/pytorch-segmentation\n",
    "\n",
    "- The implementation of the convolutional conditional random field used for postprocessing was derived from https://github.com/MarvinTeichmann/ConvCRF "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('iceseg': conda)",
   "name": "python395jvsc74a57bd055da51211d2b485401f83d8f81f53d573c41413a25f37947948be4fafcf8b118"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
